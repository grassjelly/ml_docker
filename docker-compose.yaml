services:
  base:
    runtime: nvidia
    privileged: true
    image: my-ml-project
    build:
      context: ../
      dockerfile: docker/Dockerfile
    environment:
      - DISPLAY=${DISPLAY:-:200}
    volumes:
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - $HOME/.Xauthority:/root/.Xauthority
    devices:
      - /dev:/dev

  kasmvnc:
    container_name: kasmvnc
    image: ghcr.io/linuxserver/baseimage-kasmvnc:alpine318
    privileged: true
    network_mode: host
    volumes:
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
      - $HOME/.Xauthority:/root/.Xauthority
    environment:
      - DISPLAY=:200
    devices:
      - /dev/dri:/dev/dri

  dev:
    container_name: dev
    extends: base
    command: sleep infinity
    depends_on: 
      - kasmvnc
    volumes:
      - ../:/app

  cuda-test:
    container_name: cuda-test
    extends: base
    command: python -c "import torch; print(torch.cuda.is_available())"
  
  jupyterlab:
    container_name: jupyterlab
    extends: base
    command: jupyter lab --allow-root --ip=0.0.0.0
    ports:
      - 8888:8888

  test:
    container_name: test
    extends: base
    command: python test.py
